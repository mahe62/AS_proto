{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahe62/AS_proto/blob/main/crawl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLxD15XIgMif",
        "outputId": "00d65017-80dc-4652-e0be-4c0c62d367a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "# !pip install tweepy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0SiPc8Y2jx57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8Y8YrMFUgMil"
      },
      "outputs": [],
      "source": [
        "#Importing packages and libraries\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQFpkJidgMim",
        "outputId": "3c3e5520-d870-499a-f7a9-f3da8c7a6eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "re.compile('[üòÄ-üôèüåÄ-üóøüöÄ-\\U0001f6ff\\U0001f1e0-üáø]+')\n"
          ]
        }
      ],
      "source": [
        "# Create a hashtags list\n",
        "hashtags = []\n",
        "\n",
        "# Create a search list\n",
        "search_list = [\"omicron\"]\n",
        "\n",
        "\n",
        "# Get the necessary API information from a text file\n",
        "# with open('../twitter_api.txt') as file:\n",
        "#     consumer_key, consumer_key_secret, access_token, access_token_secret = [line.strip('\\n').split('=')[1] for line in\n",
        "#                                                                             file.readlines()]\n",
        "access_token=\"?????\"\n",
        "access_token_secret=\"???\"\n",
        "consumer_key=\"???\"\n",
        "consumer_key_secret=\"???\"\n",
        "\n",
        "# Setup tweepy with Twitter credentials\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_key_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "import re\n",
        "\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "print(emoji_pattern)\n",
        "\n",
        "# Define a function to get tweets\n",
        "def get_tweets(search, isHashtag):\n",
        "    # Create a pandas DataFrame\n",
        "    df_temp = pd.DataFrame(columns=[\"Username\", \"Location\", \"Created at\", \"Content\"])\n",
        "\n",
        "    # Get the tweets\n",
        "    tweets = tweepy.Cursor(api.search, q=search + \" -filter:retweets\", lang=\"id\", since=\"2022-02-04\",\n",
        "                           tweet_mode='extended').items(50)\n",
        "\n",
        "    # Iterate over tweets\n",
        "    for tweet in tweets:\n",
        "        # content = tweet.full_text\n",
        "        content = tweet.full_text.lower()\n",
        "        content = re.sub(r\"http\\S+\", \"\", content)\n",
        "        content = content.replace(\"‚Ä¶\", \"\")\n",
        "        content = content.strip()\n",
        "        content = content.replace('\\n', ' ')\n",
        "        # clean_words = [word for word in sentences if word not in set(string.punctuation)]\n",
        "        # characters_to_remove = [\"''\", '``', '...']\n",
        "        # clean_words = [word for word in clean_words if word not in set(characters_to_remove)]\n",
        "        # characters_to_remove2 = [word for word in clean_words if any(letter in sentences for letter in '\\\\')]\n",
        "        # clean_words = [word for word in clean_words if word not in set(characters_to_remove2)]\n",
        "        # print(clean_words)\n",
        "        contents = content\n",
        "        username = tweet.user.screen_name\n",
        "        location = tweet.user.location\n",
        "        created_at = tweet.created_at\n",
        "\n",
        "        # Create a list consists of the features\n",
        "        retrieved = [username, location, created_at, contents]\n",
        "\n",
        "        # Append list to the DataFrame\n",
        "        df_temp.loc[len(df_temp)] = retrieved\n",
        "\n",
        "    # Generate unique filename\n",
        "    path = os.getcwd()\n",
        "\n",
        "    # Generate a filename for hashtags or specific word\n",
        "    if isHashtag:\n",
        "        filename = path + '/' + search[1:] + '_hashtag.csv'\n",
        "    else:\n",
        "        filename = path + '/' + search.replace(\" \", \"\") + '_wordsearch2.csv'\n",
        "    # Save the csv file\n",
        "    df_temp.to_csv(filename)\n",
        "\n",
        "\n",
        "# Call get_tweets function for each hashtag and search word\n",
        "\n",
        "for hashtag in hashtags:\n",
        "    get_tweets(hashtag, isHashtag=True)\n",
        "\n",
        "for search in search_list:\n",
        "    get_tweets(search, isHashtag=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "crawl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}